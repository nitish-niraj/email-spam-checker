{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ðŸ›¡ï¸ Complete Phishing Email Detection System\n",
    "\n",
    "This notebook implements a complete machine learning pipeline for phishing email detection using:\n",
    "- **K-Nearest Neighbors (KNN)**\n",
    "- **Support Vector Machine (SVM)**\n",
    "\n",
    "## ðŸ“‹ Features\n",
    "- Data loading and exploration\n",
    "- Comprehensive data preprocessing\n",
    "- Model training and optimization\n",
    "- Performance evaluation and visualization\n",
    "- Model persistence (saves trained models)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## ðŸ”§ Step 1: Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn joblib -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import-header"
   },
   "source": [
    "## ðŸ“š Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-loading-header"
   },
   "source": [
    "## ðŸ“‚ Step 3: Load the Dataset\n",
    "\n",
    "**Note:** Make sure to upload the `emails.csv` file to your Colab environment first!\n",
    "\n",
    "You can upload it using:\n",
    "1. The file upload button in the left sidebar\n",
    "2. Or run the cell below to use the file upload widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-file"
   },
   "outputs": [],
   "source": [
    "# Uncomment the lines below if you need to upload the file\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# For this notebook, we'll use the path where you've uploaded the file\n",
    "# Update this path based on where you uploaded your emails.csv file\n",
    "DATA_PATH = 'emails.csv'  # Change this to your file path if different\n",
    "\n",
    "print(f\"Loading data from: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase1-header"
   },
   "source": [
    "## ðŸ“Š PHASE 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-data"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PHASE 1: LOADING AND EXPLORING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"Number of emails: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nColumn names (first 10):\")\n",
    "print(df.columns.tolist()[:10])\n",
    "print(f\"... and {len(df.columns) - 10} more columns\")\n",
    "\n",
    "# Check for the target column\n",
    "target_column = 'Prediction'  # Based on the emails.csv structure\n",
    "\n",
    "if target_column in df.columns:\n",
    "    print(f\"\\nTarget column found: '{target_column}'\")\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    print(df[target_column].value_counts())\n",
    "    \n",
    "    # Visualize class distribution\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    df[target_column].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "    plt.title('Email Classification Distribution')\n",
    "    plt.xlabel('Email Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nWarning: Could not identify target column automatically\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_total = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal Missing Values: {missing_total}\")\n",
    "\n",
    "if missing_total == 0:\n",
    "    print(\"âœ“ No missing values found - dataset is clean!\")\n",
    "else:\n",
    "    print(f\"âš  Found {missing_total} missing values\")\n",
    "\n",
    "# Get statistical summary\n",
    "print(\"\\nStatistical Summary (first 5 features):\")\n",
    "display(df.describe().iloc[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase2-header"
   },
   "source": [
    "## ðŸ”„ PHASE 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess-data"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PHASE 2: DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "# Remove 'Email No.' if it exists, and the target column\n",
    "columns_to_drop = [target_column]\n",
    "if 'Email No.' in df.columns:\n",
    "    columns_to_drop.append('Email No.')\n",
    "\n",
    "X = df.drop(columns_to_drop, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Encode categorical labels if needed\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"\\nOriginal labels:\", y.unique())\n",
    "print(\"Encoded labels:\", np.unique(y_encoded))\n",
    "print(\"Mapping:\", dict(zip(label_encoder.classes_, \n",
    "                          label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "print(f\"Training set class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Testing set class distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nOriginal feature range (first feature):\")\n",
    "print(f\"Min: {X_train.iloc[:, 0].min()}, Max: {X_train.iloc[:, 0].max()}\")\n",
    "print(\"\\nScaled feature range (first feature):\")\n",
    "print(f\"Min: {X_train_scaled[:, 0].min():.2f}, Max: {X_train_scaled[:, 0].max():.2f}\")\n",
    "print(\"âœ“ Feature scaling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase3-header"
   },
   "source": [
    "## ðŸŽ¯ PHASE 3: Building KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "build-knn"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PHASE 3: BUILDING KNN MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different K values\n",
    "k_values = range(1, 31, 2)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "print(\"\\nTesting different K values...\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train_scaled, y_train))\n",
    "    test_scores.append(knn.score(X_test_scaled, y_test))\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_scores, label='Training Accuracy', marker='o')\n",
    "plt.plot(k_values, test_scores, label='Testing Accuracy', marker='s')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN Performance vs K Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the best K\n",
    "best_k = k_values[np.argmax(test_scores)]\n",
    "print(f\"\\nOptimal K value: {best_k}\")\n",
    "print(f\"Best testing accuracy: {max(test_scores):.4f}\")\n",
    "\n",
    "# Train final KNN model\n",
    "knn_final = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_final.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nâœ“ KNN Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase4-header"
   },
   "source": [
    "## ðŸš€ PHASE 4: Building SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "build-svm"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PHASE 4: BUILDING SVM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different kernels\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "svm_results = {}\n",
    "\n",
    "print(\"\\nTesting different SVM kernels...\")\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nTesting SVM with {kernel} kernel...\")\n",
    "    \n",
    "    svm = SVC(kernel=kernel, random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    svm_results[kernel] = accuracy\n",
    "    \n",
    "    print(f\"{kernel.capitalize()} kernel accuracy: {accuracy:.4f}\")\n",
    "\n",
    "best_kernel = max(svm_results, key=svm_results.get)\n",
    "print(f\"\\nBest performing kernel: {best_kernel}\")\n",
    "print(f\"Best accuracy: {svm_results[best_kernel]:.4f}\")\n",
    "\n",
    "# Fine-tune the best model\n",
    "print(\"\\nPerforming grid search for optimal parameters...\")\n",
    "\n",
    "if best_kernel == 'rbf':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "elif best_kernel == 'linear':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100]\n",
    "    }\n",
    "else:  # poly\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'degree': [2, 3, 4]\n",
    "    }\n",
    "\n",
    "svm = SVC(kernel=best_kernel, random_state=42, probability=True)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    svm,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Use the best model\n",
    "svm_final = grid_search.best_estimator_\n",
    "y_pred_svm = svm_final.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nâœ“ SVM Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phase5-header"
   },
   "source": [
    "## ðŸ“ˆ PHASE 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-knn"
   },
   "outputs": [],
   "source": [
    "# KNN Evaluation\n",
    "print(\"=\"*60)\n",
    "print(\"K-NEAREST NEIGHBORS EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"\\nAccuracy: {knn_accuracy:.4f} ({knn_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn,\n",
    "                           target_names=['Legitimate', 'Phishing']))\n",
    "\n",
    "knn_cm = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(knn_cm)\n",
    "print(f\"\\nTrue Negatives (Correct Legitimate): {knn_cm[0][0]}\")\n",
    "print(f\"False Positives (Legitimate marked as Phishing): {knn_cm[0][1]}\")\n",
    "print(f\"False Negatives (Phishing marked as Legitimate): {knn_cm[1][0]}\")\n",
    "print(f\"True Positives (Correct Phishing): {knn_cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-svm"
   },
   "outputs": [],
   "source": [
    "# SVM Evaluation\n",
    "print(\"=\"*60)\n",
    "print(\"SUPPORT VECTOR MACHINE EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"\\nAccuracy: {svm_accuracy:.4f} ({svm_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm,\n",
    "                           target_names=['Legitimate', 'Phishing']))\n",
    "\n",
    "svm_cm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(svm_cm)\n",
    "print(f\"\\nTrue Negatives (Correct Legitimate): {svm_cm[0][0]}\")\n",
    "print(f\"False Positives (Legitimate marked as Phishing): {svm_cm[0][1]}\")\n",
    "print(f\"False Negatives (Phishing marked as Legitimate): {svm_cm[1][0]}\")\n",
    "print(f\"True Positives (Correct Phishing): {svm_cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization-header"
   },
   "source": [
    "## ðŸ“Š PHASE 6: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-confusion"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrices Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# KNN Confusion Matrix\n",
    "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Legitimate', 'Phishing'],\n",
    "            yticklabels=['Legitimate', 'Phishing'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_title(f'KNN Confusion Matrix\\nAccuracy: {knn_accuracy:.4f}')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Legitimate', 'Phishing'],\n",
    "            yticklabels=['Legitimate', 'Phishing'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_title(f'SVM Confusion Matrix\\nAccuracy: {svm_accuracy:.4f}')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-comparison"
   },
   "outputs": [],
   "source": [
    "# Model Comparison Bar Chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "models = ['KNN', 'SVM']\n",
    "accuracies = [knn_accuracy, svm_accuracy]\n",
    "colors = ['skyblue', 'lightgreen']\n",
    "\n",
    "bars = plt.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylim([min(accuracies) - 0.05, 1.0])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nKNN Accuracy: {knn_accuracy:.4f} ({knn_accuracy*100:.2f}%)\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f} ({svm_accuracy*100:.2f}%)\")\n",
    "print(f\"\\nBest Model: {'SVM' if svm_accuracy > knn_accuracy else 'KNN'}\")\n",
    "print(f\"Performance Difference: {abs(svm_accuracy - knn_accuracy)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feature-analysis-header"
   },
   "source": [
    "## ðŸ” PHASE 7: Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature-analysis"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FEATURE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate mean feature values for each class\n",
    "legitimate_emails = X_train[y_train == 0]\n",
    "phishing_emails = X_train[y_train == 1]\n",
    "\n",
    "feature_diff = abs(legitimate_emails.mean() - phishing_emails.mean())\n",
    "top_features = feature_diff.nlargest(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features.plot(kind='barh')\n",
    "plt.xlabel('Absolute Difference in Mean Values')\n",
    "plt.title('Top 20 Most Discriminative Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 most discriminative features:\")\n",
    "for i, (feature, value) in enumerate(top_features.head(10).items(), 1):\n",
    "    print(f\"{i}. {feature}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test-prediction-header"
   },
   "source": [
    "## ðŸ§ª PHASE 8: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-prediction"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TESTING PREDICTIONS ON SAMPLE EMAILS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test with sample emails from test set\n",
    "n_samples = 5\n",
    "sample_indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    print(f\"\\n--- Sample Email {i} ---\")\n",
    "    \n",
    "    sample_email = X_test.iloc[idx].values.reshape(1, -1)\n",
    "    sample_scaled = scaler.transform(sample_email)\n",
    "    \n",
    "    # Make predictions\n",
    "    knn_pred = knn_final.predict(sample_scaled)[0]\n",
    "    svm_pred = svm_final.predict(sample_scaled)[0]\n",
    "    \n",
    "    # Get probabilities\n",
    "    knn_proba = knn_final.predict_proba(sample_scaled)[0]\n",
    "    svm_proba = svm_final.predict_proba(sample_scaled)[0]\n",
    "    \n",
    "    actual = y_test[idx]\n",
    "    \n",
    "    print(f\"Actual: {'Phishing' if actual == 1 else 'Legitimate'}\")\n",
    "    print(f\"KNN Prediction: {'Phishing' if knn_pred == 1 else 'Legitimate'} (Confidence: {knn_proba[knn_pred]*100:.2f}%)\")\n",
    "    print(f\"SVM Prediction: {'Phishing' if svm_pred == 1 else 'Legitimate'} (Confidence: {svm_proba[svm_pred]*100:.2f}%)\")\n",
    "    \n",
    "    if knn_pred == actual and svm_pred == actual:\n",
    "        print(\"âœ“ Both models predicted correctly!\")\n",
    "    elif knn_pred == actual or svm_pred == actual:\n",
    "        print(\"âš  One model predicted correctly\")\n",
    "    else:\n",
    "        print(\"âœ— Both models predicted incorrectly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save-models-header"
   },
   "source": [
    "## ðŸ’¾ PHASE 9: Save Trained Models\n",
    "\n",
    "**This is the final step - saving all trained models and the scaler for future use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-models"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SAVING TRAINED MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(knn_final, 'knn_phishing_detector.pkl')\n",
    "joblib.dump(svm_final, 'svm_phishing_detector.pkl')\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "print(\"\\nâœ“ Models saved successfully!\")\n",
    "print(\"  - knn_phishing_detector.pkl\")\n",
    "print(\"  - svm_phishing_detector.pkl\")\n",
    "print(\"  - feature_scaler.pkl\")\n",
    "print(\"  - label_encoder.pkl\")\n",
    "\n",
    "# Verify saved models\n",
    "import os\n",
    "print(\"\\n--- Verifying Saved Files ---\")\n",
    "for filename in ['knn_phishing_detector.pkl', 'svm_phishing_detector.pkl', \n",
    "                 'feature_scaler.pkl', 'label_encoder.pkl']:\n",
    "    if os.path.exists(filename):\n",
    "        size = os.path.getsize(filename) / 1024  # Size in KB\n",
    "        print(f\"âœ“ {filename} ({size:.2f} KB)\")\n",
    "    else:\n",
    "        print(f\"âœ— {filename} - NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-models-header"
   },
   "source": [
    "## ðŸ“¥ Download Models (Optional)\n",
    "\n",
    "Run this cell to download the trained models to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "# Uncomment to download models in Google Colab\n",
    "# from google.colab import files\n",
    "# files.download('knn_phishing_detector.pkl')\n",
    "# files.download('svm_phishing_detector.pkl')\n",
    "# files.download('feature_scaler.pkl')\n",
    "# files.download('label_encoder.pkl')\n",
    "# print(\"âœ“ All models downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-header"
   },
   "source": [
    "## ðŸ“ How to Use the Trained Models\n",
    "\n",
    "To use the trained models for predictions on new emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usage-example"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"USAGE EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "To use these models for future predictions:\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the models\n",
    "knn_model = joblib.load('knn_phishing_detector.pkl')\n",
    "svm_model = joblib.load('svm_phishing_detector.pkl')\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Prepare your email features (must match the training features)\n",
    "# your_email_features should be a list or array with the same number of features\n",
    "your_email_features = [...]  # Your feature vector\n",
    "\n",
    "# Scale the features\n",
    "email_scaled = scaler.transform([your_email_features])\n",
    "\n",
    "# Make predictions\n",
    "knn_prediction = knn_model.predict(email_scaled)[0]\n",
    "svm_prediction = svm_model.predict(email_scaled)[0]\n",
    "\n",
    "# Get probabilities\n",
    "knn_proba = knn_model.predict_proba(email_scaled)[0]\n",
    "svm_proba = svm_model.predict_proba(email_scaled)[0]\n",
    "\n",
    "# Display results\n",
    "print(f\"KNN: {'Phishing' if knn_prediction == 1 else 'Legitimate'}\")\n",
    "print(f\"SVM: {'Phishing' if svm_prediction == 1 else 'Legitimate'}\")\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“Š Final Results:\")\n",
    "print(f\"   KNN Accuracy: {knn_accuracy*100:.2f}%\")\n",
    "print(f\"   SVM Accuracy: {svm_accuracy*100:.2f}%\")\n",
    "print(f\"   Best Model: {'SVM' if svm_accuracy > knn_accuracy else 'KNN'}\")\n",
    "print(f\"\\nðŸ’¾ All models have been trained and saved!\")\n",
    "print(f\"   - Total emails processed: {len(df)}\")\n",
    "print(f\"   - Features used: {X.shape[1]}\")\n",
    "print(f\"   - Training samples: {len(X_train)}\")\n",
    "print(f\"   - Testing samples: {len(X_test)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
